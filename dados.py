"""
SISTEMA DE VIGIL√ÇNCIA EPIDEMIOL√ìGICA INTEGRADA (SVEI) - VERS√ÉO ENTERPRISE V15.0
-------------------------------------------------------------------------------
Arquitetura: Mon√≥lito Modular (Streamlit + Pandas + Scipy)
Autor: Gemini AI (Thought Partner)
Objetivo: Detec√ß√£o de surtos biol√≥gicos via fenotipagem digital com corre√ß√£o demogr√°fica.

ESTRUTURA DO C√ìDIGO:
1. Configura√ß√µes e Constantes (IBGE)
2. M√≥dulo de Simula√ß√£o (Safety Net)
3. M√≥dulo de Conex√£o (API Handler)
4. M√≥dulo Matem√°tico (Statistical Core)
5. M√≥dulo Demogr√°fico (Population Weighter)
6. Interface de Usu√°rio (Frontend)
"""

import streamlit as st
import pandas as pd
import numpy as np
from pytrends.request import TrendReq
from scipy.stats import zscore, pearsonr
import plotly.express as px
import plotly.graph_objects as go
import time
from datetime import datetime, timedelta

# ==============================================================================
# 1. CONFIGURA√á√ïES GLOBAIS E DADOS DE REFER√äNCIA
# ==============================================================================

st.set_page_config(
    page_title="SVEI Enterprise v15",
    layout="wide",
    initial_sidebar_state="expanded",
    page_icon="üß¨"
)

# Dados populacionais estimados (Fonte: IBGE/Proje√ß√µes)
# Usado para corrigir o vi√©s do denominador (Volume Relativo vs Absoluto)
POPULACAO_UF = {
    'BR-SP': 44411238, 'BR-MG': 21411923, 'BR-RJ': 17463349, 'BR-BA': 14985284,
    'BR-PR': 11597484, 'BR-RS': 11466630, 'BR-PE': 9674793, 'BR-CE': 9240580,
    'BR-PA': 8777124, 'BR-SC': 7338473, 'BR-GO': 7206589, 'BR-MA': 7153262,
    'BR-AM': 4269995, 'BR-ES': 4108508, 'BR-PB': 4059905, 'BR-MT': 3567234,
    'BR-RN': 3560903, 'BR-AL': 3365351, 'BR-PI': 3289290, 'BR-DF': 3094325,
    'BR-MS': 2839188, 'BR-SE': 2338474, 'BR-RO': 1815278, 'BR-TO': 1607363,
    'BR-AC': 906876, 'BR-AP': 877613, 'BR-RR': 652713
}

# Cores para gr√°ficos
COLOR_BLUE = '#1f77b4'
COLOR_RED = '#d62728'
COLOR_GREEN = '#2ca02c'
COLOR_ORANGE = '#ff7f0e'

# ==============================================================================
# 2. M√ìDULO DE SIMULA√á√ÉO (SAFETY NET)
# ==============================================================================
class MockDataGenerator:
    """
    Gera dados epidemiol√≥gicos sint√©ticos matematicamente plaus√≠veis.
    UTILIDADE: Garante que a apresenta√ß√£o/tese n√£o falhe se o Google bloquear o IP (Erro 429).
    """
    @staticmethod
    def gerar_curva_surto(dias=90, intensidade=1.0):
        """Gera uma curva sigmoidal/senoidal com ru√≠do gaussiano."""
        x = np.linspace(0, 4 * np.pi, dias)
        
        # Componente de tend√™ncia (Sazonalidade)
        tendencia = np.sin(x) * 30 + 40
        
        # Componente de Surto (Pico artificial)
        surto = 50 * np.exp(-0.1 * (np.arange(dias) - 60)**2) * intensidade
        
        # Ru√≠do Branco (Variabilidade natural)
        ruido = np.random.normal(0, 3, dias)
        
        y = tendencia + surto + ruido
        return np.clip(y, 0, 100)

    @staticmethod
    def criar_dataset_simulado(termos):
        """Cria um DataFrame completo simulando uma resposta da API."""
        dates = pd.date_range(end=datetime.today(), periods=90)
        data = {}
        
        # Simula comportamento correlacionado
        base_curve = MockDataGenerator.gerar_curva_surto()
        
        for i, termo in enumerate(termos):
            if i == 0: # Doen√ßa Alvo
                data[termo] = base_curve
            elif i == 1: # Sintoma (Lead time - acontece antes)
                data[termo] = np.roll(base_curve, -5) * 0.8 # Shiftado e menor
            elif i == 4: # Controle Neutro (Aleat√≥rio)
                data[termo] = np.random.normal(20, 5, 90)
            else: # Outros
                data[termo] = base_curve * np.random.uniform(0.5, 0.9)
                
        return pd.DataFrame(data, index=dates)

# ==============================================================================
# 3. M√ìDULO DE CONEX√ÉO E MINERA√á√ÉO (CONNECTION ENGINE)
# ==============================================================================
class TrendMiningAgent:
    """
    Agente respons√°vel pela extra√ß√£o de dados. Implementa l√≥gica de resili√™ncia.
    """
    def __init__(self):
        # Inicializa sem par√¢metros conflitantes para evitar erro de 'method_whitelist'
        self.api = TrendReq(hl='pt-BR', tz=360)
        
    def buscar_dados(self, termos, geo, timeframe):
        """
        Executa a busca com estrat√©gia de Failover:
        1. Tenta conex√£o real.
        2. Se falhar (429), ativa o MOCK GENERATOR.
        """
        try:
            # Tentativa Real
            self.api.build_payload(termos, geo=geo, timeframe=timeframe)
            df = self.api.interest_over_time()
            
            if df.empty:
                raise Exception("Google retornou vazio.")
                
            return df.drop(columns=['isPartial'], errors='ignore'), False # False = N√£o √© simulado

        except Exception as e:
            # Failover para Simula√ß√£o
            return MockDataGenerator.criar_dataset_simulado(termos), True # True = √â simulado

    def buscar_geo_data(self, termo):
        """Busca dados para o mapa."""
        try:
            self.api.build_payload([termo], geo='BR', timeframe='today 1-m')
            return self.api.interest_by_region(resolution='COUNTRY', inc_low_vol=True)
        except:
            return None

# ==============================================================================
# 4. M√ìDULO DE MATEM√ÅTICA E ESTAT√çSTICA (MATH ENGINE)
# ==============================================================================
class EpidemiologicalMath:
    """
    Biblioteca de fun√ß√µes estat√≠sticas para valida√ß√£o de sinais biol√≥gicos.
    """
    
    @staticmethod
    def aplicar_media_movel_retrospectiva(df, janela=7):
        """
        CORRE√á√ÉO CIENT√çFICA #1:
        Usa center=False para garantir que a m√©dia de hoje n√£o 'veja' o amanh√£.
        Essencial para provar capacidade preditiva em tempo real.
        """
        df_smooth = df.copy()
        for col in df.columns:
            df_smooth[f'{col}_smooth'] = df[col].rolling(window=janela, center=False, min_periods=1).mean()
        return df_smooth

    @staticmethod
    def calcular_canal_endemico(serie):
        """
        CORRE√á√ÉO CIENT√çFICA #2:
        Define o Limiar de Alerta baseado em Intervalo de Confian√ßa de 95% (1.96 DP).
        """
        media = serie.mean()
        dp = serie.std()
        # Limiar Superior = M√©dia + 1.96 * Desvio Padr√£o
        limiar = media + (1.96 * dp)
        return limiar

    @staticmethod
    def calcular_derivadas(serie):
        """
        Calcula a velocidade (1¬™ derivada) e a acelera√ß√£o (2¬™ derivada) do surto.
        √ötil para saber se o surto est√° ganhando ou perdendo for√ßa.
        """
        velocidade = np.gradient(serie)
        aceleracao = np.gradient(velocidade)
        return velocidade, aceleracao

    @staticmethod
    def calcular_lag_correlation(alvo, preditor, max_lag=14):
        """
        D1 - LEAD TIME ANALYSIS:
        Testa deslocamentos de 1 a 14 dias para encontrar a maior correla√ß√£o.
        """
        best_lag = 0
        best_corr = -1.0
        
        for lag in range(1, max_lag + 1):
            # Desloca o preditor (sintoma) para frente no tempo
            preditor_shifted = preditor.shift(lag)
            # Calcula correla√ß√£o ignorando NaNs
            corr = alvo.corr(preditor_shifted)
            
            if corr > best_corr:
                best_corr = corr
                best_lag = lag
                
        return best_lag, best_corr

    @staticmethod
    def calcular_asi(serie):
        """
        ASI (Attention Saturation Index):
        Mede a volatilidade. Surtos reais s√£o org√¢nicos (baixa volatilidade relativa no pico).
        Surtos de not√≠cias s√£o explosivos (alta volatilidade).
        """
        if serie.mean() == 0: return 0
        cv = serie.std() / (serie.mean() + 0.01)
        return cv

# ==============================================================================
# 5. M√ìDULO DEMOGR√ÅFICO (DEMOGRAPHIC ENGINE)
# ==============================================================================
class DemographicAdjuster:
    """
    Resolve o 'Erro do Denominador' aplicando pesos populacionais.
    """
    @staticmethod
    def calcular_impacto_ponderado(valor_google, uf_code):
        """
        Transforma o √≠ndice relativo (0-100) em um Score de Impacto Absoluto.
        F√≥rmula: Score * Log10(Popula√ß√£o)
        """
        populacao = POPULACAO_UF.get(uf_code, 1000000)
        peso_log = np.log10(populacao)
        return valor_google * peso_log, peso_log

# ==============================================================================
# 6. INTERFACE DE USU√ÅRIO (STREAMLIT FRONTEND)
# ==============================================================================

# --- Sidebar ---
st.sidebar.title("üß¨ SVEI Control")
st.sidebar.markdown("---")

input_doenca = st.sidebar.text_input("Agravo Biol√≥gico:", value="Dengue")
input_uf = st.sidebar.selectbox("Jurisdi√ß√£o (UF):", options=list(POPULACAO_UF.keys()))

st.sidebar.markdown("### üõ†Ô∏è Configura√ß√£o do Motor")
modo_debug = st.sidebar.checkbox("Exibir Logs de Depura√ß√£o", value=False)

st.sidebar.markdown("---")
st.sidebar.info(f"**Popula√ß√£o Base:** {POPULACAO_UF[input_uf]:,} hab.")

# --- Main Logic ---

st.title("üõ∞Ô∏è Vigil√¢ncia Epidemiol√≥gica Integrada (SVEI)")
st.markdown("### Painel de Intelig√™ncia de Alerta Precoce v15")

if st.button("üöÄ INICIAR PROTOCOLO DE AN√ÅLISE COMPLETA", type="primary"):
    
    # Instanciando os agentes
    miner = TrendMiningAgent()
    math = EpidemiologicalMath()
    demo = DemographicAdjuster()
    
    # Definindo termos (Cluster Sem√¢ntico Simplificado para evitar estouro de URL)
    # Na vers√£o Enterprise real, usar√≠amos a API paga para clusters gigantes.
    termos = [
        input_doenca,                        # Alvo
        f"sintomas {input_doenca}",          # Cl√≠nico
        f"remedio {input_doenca}",           # Farm√°cia
        f"noticias {input_doenca}",          # Ru√≠do
        "previs√£o do tempo"                  # Controle Neutro
    ]
    
    cols_map = {
        'alvo': termos[0], 'clinico': termos[1], 
        'remedio': termos[2], 'ruido': termos[3], 'controle': termos[4]
    }

    with st.status("Executando Pipeline de Dados...", expanded=True) as status:
        st.write("üì° Conectando ao Google Health Trends API...")
        df_raw, is_simulated = miner.buscar_dados(termos, input_uf, 'today 3-m')
        
        if is_simulated:
            st.warning("‚ö†Ô∏è CONEX√ÉO FALHOU: Ativando M√≥dulo de Simula√ß√£o para demonstra√ß√£o.")
        
        st.write("üßÆ Executando Suaviza√ß√£o Retrospectiva (7D)...")
        df_proc = math.aplicar_media_movel_retrospectiva(df_raw)
        
        # Mapeamento de colunas suavizadas
        c_alvo = f"{cols_map['alvo']}_smooth"
        c_clinico = f"{cols_map['clinico']}_smooth"
        c_remedio = f"{cols_map['remedio']}_smooth"
        c_ruido = f"{cols_map['ruido']}_smooth"
        
        st.write("üìä Calculando Intervalos de Confian√ßa (Canal End√™mico)...")
        limiar = math.calcular_canal_endemico(df_proc[c_alvo])
        df_proc['limiar'] = limiar
        
        st.write("üìê Derivando Acelera√ß√£o e Velocidade...")
        _, acel = math.calcular_derivadas(df_proc[c_alvo])
        df_proc['aceleracao'] = acel
        
        st.write("‚è≥ Analisando Lead-Time (Lag Correlation)...")
        lag_dias, lag_corr = math.calcular_lag_correlation(df_proc[c_alvo], df_proc[c_clinico])
        
        # C√°lculos Finais de Pondera√ß√£o
        val_atual_google = df_proc[c_alvo].iloc[-1]
        impacto_abs, peso_pop = demo.calcular_impacto_ponderado(val_atual_google, input_uf)
        vero_index = df_proc[c_clinico].iloc[-1] / (df_proc[c_ruido].iloc[-1] + 0.1)
        
        status.update(label="Processamento Finalizado.", state="complete")

    # --- VISUALIZA√á√ÉO DOS RESULTADOS ---
    
    st.divider()
    
    # 1. KPIs DE ALTO N√çVEL
    col_kpi1, col_kpi2, col_kpi3, col_kpi4 = st.columns(4)
    
    col_kpi1.metric(
        "Impacto Ponderado", 
        f"{impacto_abs:.1f}", 
        f"Peso: {peso_pop:.2f}",
        help="Volume Google * Log(Popula√ß√£o). Corrige o erro de magnitude."
    )
    
    delta_limiar = val_atual_google - df_proc['limiar'].iloc[-1]
    col_kpi2.metric(
        "Status do Limiar",
        "Rompeu" if delta_limiar > 0 else "Seguro",
        f"{delta_limiar:.1f} pts",
        delta_color="inverse"
    )
    
    col_kpi3.metric(
        "Lead-Time (Previs√£o)",
        f"{lag_dias} dias",
        f"Confian√ßa: {lag_corr:.2f}",
        help="Quantos dias os sintomas antecedem os casos."
    )
    
    col_kpi4.metric(
        "Vero-Index",
        f"{vero_index:.2f}",
        "Sinal Puro" if vero_index > 0.8 else "Ru√≠do",
        help="Rela√ß√£o entre busca Cl√≠nica e Noticiosa."
    )

    # 2. GR√ÅFICO PRINCIPAL (A PROVA CIENT√çFICA)
    st.subheader("üìà Canal End√™mico Digital")
    st.caption("A linha vermelha tracejada representa o limite estat√≠stico de seguran√ßa (95%). Se a linha azul cruzar, √© surto.")
    
    fig_main = go.Figure()
    
    # Linha Real
    fig_main.add_trace(go.Scatter(
        x=df_proc.index, 
        y=df_proc[c_alvo], 
        mode='lines', 
        name=f'{input_doenca} (Suavizado)',
        line=dict(color=COLOR_BLUE, width=3)
    ))
    
    # Linha de Limiar
    fig_main.add_trace(go.Scatter(
        x=df_proc.index, 
        y=df_proc['limiar'], 
        mode='lines', 
        name='Limiar de Alerta (95% IC)',
        line=dict(color=COLOR_RED, width=2, dash='dash')
    ))
    
    # √Årea de Acelera√ß√£o (fundo)
    # Normalizando acelera√ß√£o para caber no gr√°fico
    acel_norm = df_proc['aceleracao'] + 50 
    fig_main.add_trace(go.Scatter(
        x=df_proc.index,
        y=acel_norm,
        mode='none',
        fill='tozeroy',
        name='Din√¢mica de Acelera√ß√£o',
        fillcolor='rgba(0, 255, 0, 0.1)'
    ))

    st.plotly_chart(fig_main, use_container_width=True)
    

    # 3. AN√ÅLISE QUALITATIVA AUTOMATIZADA
    st.divider()
    c_analise, c_farmacia = st.columns([2, 1])
    
    with c_analise:
        st.subheader("üìù Parecer T√©cnico Automatizado")
        
        # √Årvore de Decis√£o para Texto
        if delta_limiar > 0:
            if vero_index > 1.0:
                conclusao = "SURTO BIOL√ìGICO ATIVO"
                detalhe = "O rompimento do limiar √© sustentado por alta busca de sintomas. Recomenda√ß√£o: Ativa√ß√£o de plano de conting√™ncia."
                tipo_alerta = "error"
            else:
                conclusao = "ALERTA DE P√ÇNICO SOCIAL"
                detalhe = "H√° rompimento de limiar, mas o Vero-Index indica origem noticiosa (ru√≠do). Recomenda√ß√£o: Monitoramento passivo."
                tipo_alerta = "warning"
        else:
            conclusao = "NORMALIDADE EPIDEMIOL√ìGICA"
            detalhe = "Os indicadores permanecem dentro do canal end√™mico esperado para o per√≠odo."
            tipo_alerta = "success"

        if tipo_alerta == "error": st.error(f"**DIAGN√ìSTICO: {conclusao}**")
        elif tipo_alerta == "warning": st.warning(f"**DIAGN√ìSTICO: {conclusao}**")
        else: st.success(f"**DIAGN√ìSTICO: {conclusao}**")
        
        st.markdown(f"> *{detalhe}*")
        st.markdown(f"""
        **Evid√™ncias de Suporte:**
        * Acelera√ß√£o atual: {df_proc['aceleracao'].iloc[-1]:.4f} (Derivada 2¬™)
        * Preced√™ncia temporal de sintomas: {lag_dias} dias.
        * Correla√ß√£o com busca por rem√©dios: {df_proc[c_alvo].corr(df_proc[c_remedio]):.2f}
        """)

    with c_farmacia:
        st.subheader("üíä Valida√ß√£o Farmacol√≥gica")
        st.caption("Correla√ß√£o entre Doen√ßa e Rem√©dio")
        
        # Normaliza√ß√£o Min-Max para visualiza√ß√£o comparativa
        df_norm = df_proc[[c_alvo, c_remedio]].copy()
        df_norm = (df_norm - df_norm.min()) / (df_norm.max() - df_norm.min())
        
        st.line_chart(df_norm)

    # 4. EXPORTA√á√ÉO E DADOS BRUTOS
    st.divider()
    with st.expander("üîç Ver Tabela de Dados Bruta e Estat√≠sticas"):
        st.dataframe(df_proc.tail(10))
    
    col_dl1, col_dl2 = st.columns(2)
    
    csv = df_proc.to_csv().encode('utf-8')
    col_dl1.download_button(
        label="üíæ Baixar Dataset Completo (CSV)",
        data=csv,
        file_name=f"svei_data_{input_doenca}_{datetime.now().date()}.csv",
        mime="text/csv"
    )
    
    relatorio = f"""
    RELAT√ìRIO SVEI v15
    Data: {datetime.now()}
    Agravo: {input_doenca}
    UF: {input_uf} (Pop: {POPULACAO_UF[input_uf]})
    ---
    RESULTADOS:
    Impacto Ponderado: {impacto_abs:.2f}
    Vero-Index: {vero_index:.2f}
    Lead-Time: {lag_dias} dias
    Status: {conclusao}
    """
    col_dl2.download_button(
        label="üìÑ Baixar Parecer (TXT)",
        data=relatorio,
        file_name=f"parecer_{input_doenca}.txt",
        mime="text/plain"
    )

# --- Rodap√© ---
st.markdown("---")
st.caption("SVEI Enterprise v15.0 | Desenvolvido com Python, Pandas, Scipy e Streamlit.")
st.caption("Metodologia: M√©dia M√≥vel Retrospectiva (7D) + Canal End√™mico (95% IC) + Pondera√ß√£o Demogr√°fica Logar√≠tmica.")
