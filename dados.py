import streamlit as st
import pandas as pd
import numpy as np
from pytrends.request import TrendReq
import plotly.express as px
import plotly.graph_objects as go
from scipy.stats import pearsonr
import time
from datetime import datetime, timedelta

# --- CONFIGURA√á√ÉO DA INTERFACE ---
st.set_page_config(page_title="Vigil√¢ncia Epidemiol√≥gica Avan√ßada", layout="wide")
st.title("üî¨ Plataforma de Vigil√¢ncia Digital e Valida√ß√£o Epidemiol√≥gica")
st.markdown("""
Esta plataforma realiza a varredura proativa de s√≠ndromes e valida a efic√°cia dos rumores digitais 
cruzando-os com dados reais de interna√ß√µes.
""")

# --- MOTOR DE BUSCA (BACKEND) ---
try:
    pytrends = TrendReq(hl='pt-BR', tz=360)
except:
    st.error("Erro ao conectar ao Google. Tente novamente em instantes.")

# --- DICION√ÅRIO DE VIGIL√ÇNCIA (SINDROMES) ---
SINDROMES = {
    "Arboviroses (Dengue/Zika)": ["dengue", "sintomas dengue", "dor atr√°s dos olhos"],
    "S√≠ndrome Respirat√≥ria": ["gripe", "falta de ar", "tosse seca", "influenza"],
    "S√≠ndrome Gastrointestinal": ["diarreia", "v√¥mito", "enjoo", "dor abdominal"],
    "Doen√ßas Exantem√°ticas": ["manchas vermelhas", "sarampo", "rub√©ola"]
}

# --- SIDEBAR: INPUT DE DADOS REAIS ---
st.sidebar.header("üìÇ Valida√ß√£o de Dados Reais")
st.sidebar.markdown("Para calcular a correla√ß√£o, suba uma planilha com as colunas **'Data'** e **'Internacoes'**.")
arquivo_real = st.sidebar.file_uploader("Upload de dados do SINAN/Hospitais", type=['csv', 'xlsx'])

# --- ABA PRINCIPAL: VARREDURA ---
if st.button("üöÄ INICIAR VARREDURA INTEGRAL E AN√ÅLISE DE CORRELA√á√ÉO"):
    resultados_globais = []
    
    with st.status("Processando intelig√™ncia de dados...", expanded=True) as status:
        for nome_s, termos in SINDROMES.items():
            st.write(f"Analisando: {nome_s}...")
            
            # 1. Coleta Temporal (√öltimos 90 dias)
            pytrends.build_payload(termos, geo='BR-MS', timeframe='today 3-m')
            df_trends = pytrends.interest_over_time()
            
            # 2. Coleta Regional (Para o Mapa de Calor)
            pytrends.build_payload([termos[0]], geo='BR', timeframe='today 1-m')
            df_regiao = pytrends.interest_by_region(resolution='COUNTRY', inc_low_vol=True)
            
            if not df_trends.empty:
                # Processamento de M√©dias
                df_trends['media_sindrome'] = df_trends[termos].mean(axis=1)
                hoje = df_trends['media_sindrome'].iloc[-1]
                media_historica = df_trends['media_sindrome'].mean()
                desvio_padrao = df_trends['media_sindrome'].std()
                z_score = (hoje - media_historica) / desvio_padrao if desvio_padrao > 0 else 0
                
                resultados_globais.append({
                    "nome": nome_s,
                    "z_score": z_score,
                    "hoje": hoje,
                    "df": df_trends,
                    "mapa": df_regiao
                })
            time.sleep(1.5) # Prote√ß√£o de taxa de acesso
        status.update(label="An√°lise Conclu√≠da!", state="complete")

    if resultados_globais:
        # --- IDENTIFICA√á√ÉO DO AGRAVO PRIORIT√ÅRIO ---
        resultados_globais.sort(key=lambda x: x['z_score'], reverse=True)
        critico = resultados_globais[0]

        # --- SE√á√ÉO 1: PARECER T√âCNICO DETALHADO ---
        st.header("üìù Parecer Anal√≠tico de Vigil√¢ncia")
        col_txt, col_metric = st.columns([3, 1])
        
        with col_txt:
            interpreta√ß√£o = "est√°vel" if critico['z_score'] < 1.5 else "em alerta moderado" if critico['z_score'] < 2.5 else "em estado cr√≠tico de surto"
            st.markdown(f"""
            O sistema realizou a varredura em 4 grandes grupos sindr√¥micos. O grupo com maior desvio detectado foi **{critico['nome']}**. 
            
            **An√°lise Estat√≠stica:** O valor atual apresenta um **Z-Score de {critico['z_score']:.2f}**. Na epidemiologia digital, valores acima de 2.0 indicam que o volume de buscas rompeu o canal end√™mico hist√≥rico. 
            Este aumento sugere uma circula√ß√£o viral ativa no estado, precedendo o pico de notifica√ß√µes oficiais em aproximadamente 7 a 14 dias.
            """)
        
        with col_metric:
            st.metric("√çndice de Anomalia", f"{critico['z_score']:.2f}", delta="Cr√≠tico" if critico['z_score'] > 2 else "Normal")

        # --- SE√á√ÉO 2: MAPA DE CALOR (MAPA REAL POR ESTADO) ---
        st.subheader("üó∫Ô∏è Dissemina√ß√£o Geogr√°fica Nacional")
        df_mapa_res = critico['mapa'].reset_index()
        
        fig_mapa = px.choropleth(
            df_mapa_res,
            geojson="https://raw.githubusercontent.com/codeforamerica/click_that_hood/master/public/data/brazil-states.geojson",
            locations='geoName',
            featureidkey="properties.name",
            color=df_mapa_res.columns[1],
            color_continuous_scale="Reds",
            scope="south america",
            labels={'geoName': 'Estado', df_mapa_res.columns[1]: 'Intensidade'}
        )
        fig_mapa.update_geos(fitbounds="locations", visible=False)
        st.plotly_chart(fig_mapa, use_container_width=True)
        

        # --- SE√á√ÉO 3: VALIDA√á√ÉO POR CORRELA√á√ÉO (DADOS REAIS) ---
        st.divider()
        st.header("üìä Valida√ß√£o Cient√≠fica: Rumores vs. Interna√ß√µes")
        
        if arquivo_real:
            # Processamento da Planilha
            df_interno = pd.read_csv(arquivo_real) if arquivo_real.name.endswith('csv') else pd.read_excel(arquivo_real)
            df_interno['Data'] = pd.to_datetime(df_interno['Data'])
            
            # Alinhamento das s√©ries
            df_google = critico['df'].reset_index()
            df_google['date'] = pd.to_datetime(df_google['date'])
            
            df_merge = pd.merge(df_google, df_interno, left_on='date', right_on='Data')
            
            if not df_merge.empty:
                # C√°lculo de Pearson
                coef_p, p_valor = pearsonr(df_merge['media_sindrome'], df_merge['Internacoes'])
                
                c1, c2 = st.columns([1, 2])
                with c1:
                    st.write("### Coeficiente de Pearson")
                    st.title(f"R = {coef_p:.3f}")
                    if coef_p > 0.7:
                        st.success("‚úÖ **Correla√ß√£o Forte:** O Google Trends √© um preditor confi√°vel para interna√ß√µes neste agravo.")
                    else:
                        st.warning("‚ö†Ô∏è **Correla√ß√£o Fraca:** Os dados digitais e hospitalares n√£o est√£o sincronizados.")
                
                with c2:
                    # Gr√°fico de Duplo Eixo
                    fig_dual = go.Figure()
                    fig_dual.add_trace(go.Scatter(x=df_merge['date'], y=df_merge['media_sindrome'], name="Buscas Google", line=dict(color='blue')))
                    fig_dual.add_trace(go.Scatter(x=df_merge['date'], y=df_merge['Internacoes'], name="Interna√ß√µes Reais", line=dict(color='red'), yaxis="y2"))
                    
                    fig_dual.update_layout(
                        title="Sincronia Temporal: Rumores vs. Fatos",
                        yaxis=dict(title="Volume de Buscas"),
                        yaxis2=dict(title="N¬∫ Interna√ß√µes", overlaying="y", side="right")
                    )
                    st.plotly_chart(fig_dual, use_container_width=True)
            else:
                st.error("As datas da planilha n√£o coincidem com os dados capturados do Google.")
        else:
            st.info("Suba uma planilha de interna√ß√µes na barra lateral para ver a valida√ß√£o estat√≠stica aqui.")

        # --- SE√á√ÉO 4: COMPARATIVO GERAL ---
        st.subheader("üìà Monitoramento Comparativo de S√≠ndromes")
        df_all = pd.DataFrame({r['nome']: r['df']['media_sindrome'] for r in resultados_globais})
        st.line_chart(df_all)
